{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Chatbot Demo\n",
    "\n",
    "This notebook demonstrates how to use the LLM Chatbot project. You'll learn how to:\n",
    "1. Set up and initialize the chatbot\n",
    "2. Interact with the chatbot in the notebook\n",
    "3. Customize the chatbot configuration\n",
    "4. Launch the web interface\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Initialization\n",
    "\n",
    "First, let's make sure we have the project in our path and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /Users/harshsisodia/Desktop/LLM_CHATBOT_PROJECT\n",
      "Files in project directory: ['app', 'requirements.txt', 'utils', 'models', 'docs', 'README.md', '.gitignore', 'data']\n"
     ]
    }
   ],
   "source": [
    "# Add the project directory to the path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Update this path to where you extracted the LLM_CHATBOT_PROJECT\n",
    "project_path = \"../LLM_CHATBOT_PROJECT\"\n",
    "sys.path.append(project_path)\n",
    "\n",
    "# Verify the path is correct\n",
    "print(f\"Project path: {os.path.abspath(project_path)}\")\n",
    "print(f\"Files in project directory: {os.listdir(project_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, setuptools, networkx, MarkupSafe, jinja2, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [torch]32m6/7\u001b[0m [torch]]x]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 setuptools-80.9.0 sympy-1.14.0 torch-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshsisodia/Desktop/LLM_CHATBOT_PROJECT 2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.52.3\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install torch transformers\n",
    "\n",
    "from app.config import Config\n",
    "from app.chatbot import Chatbot\n",
    "\n",
    "# Check if transformers is installed\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Transformers not installed. Please run: %pip install transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Chatbot\n",
    "\n",
    "Now, let's initialize the chatbot with a configuration. We'll use a smaller model for faster loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'model_name': 'distilgpt2', 'max_response_length': 50, 'temperature': 0.7, 'max_history_length': 10, 'save_conversations': True, 'conversation_dir': '/Users/harshsisodia/Desktop/LLM_CHATBOT_PROJECT 2/data/conversations', 'web_host': '0.0.0.0', 'web_port': 8000, 'debug': False}\n"
     ]
    }
   ],
   "source": [
    "# Create a configuration\n",
    "config = Config()\n",
    "\n",
    "# Use a smaller model for faster loading\n",
    "config.model_name = \"distilgpt2\"  # Smaller than full GPT-2\n",
    "config.max_response_length = 50   # Shorter responses for demonstration\n",
    "config.temperature = 0.7          # Controls randomness (0.0 = deterministic, 1.0 = random)\n",
    "\n",
    "print(f\"Configuration: {config.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing chatbot (this may take a moment to download the model)...\n",
      "Loading model: distilgpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully: distilgpt2\n",
      "Chatbot initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the chatbot\n",
    "# Note: This will download the model if it's not already cached locally\n",
    "# It might take a few minutes the first time\n",
    "print(\"Initializing chatbot (this may take a moment to download the model)...\")\n",
    "chatbot = Chatbot(config)\n",
    "print(\"Chatbot initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interact with the Chatbot\n",
    "\n",
    "Let's create a simple function to interact with the chatbot and try some example conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chat with the bot\n",
    "def chat_with_bot(message):\n",
    "    print(f\"\\nUser: {message}\")\n",
    "    response = chatbot.generate_response(message)\n",
    "    print(f\"Bot: {response}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Chatbot' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \tchatbot = Chatbot(config)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Start a conversation using the correct method\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m response = \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mHello, how are you today?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Chatbot' object has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "# Let's start a conversation\n",
    "\n",
    "# Ensure chatbot is initialized\n",
    "# Import necessary components\n",
    "from app.config import Config\n",
    "from app.chatbot import Chatbot\n",
    "\n",
    "# Initialize chatbot if not already done\n",
    "if 'chatbot' not in globals():\n",
    "\tconfig = Config()\n",
    "\tconfig.model_name = \"distilgpt2\"\n",
    "\tconfig.max_response_length = 50\n",
    "\tconfig.temperature = 0.7\n",
    "\tchatbot = Chatbot(config)\n",
    "\n",
    "# Start a conversation using the correct method\n",
    "response = chatbot.chat(\"Hello, how are you today?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: Tell me about artificial intelligence.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chatbot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ask about a topic\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mchat_with_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTell me about artificial intelligence.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mchat_with_bot\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat_with_bot\u001b[39m(message):\n\u001b[32m      3\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \tresponse = \u001b[43mchatbot\u001b[49m.generate_response(message)\n\u001b[32m      5\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mNameError\u001b[39m: name 'chatbot' is not defined"
     ]
    }
   ],
   "source": [
    "# Ask about a topic\n",
    "chat_with_bot(\"Tell me about artificial intelligence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: What are some applications of this technology?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chatbot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ask a follow-up question to test context awareness\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mchat_with_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat are some applications of this technology?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mchat_with_bot\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat_with_bot\u001b[39m(message):\n\u001b[32m      3\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \tresponse = \u001b[43mchatbot\u001b[49m.generate_response(message)\n\u001b[32m      5\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mNameError\u001b[39m: name 'chatbot' is not defined"
     ]
    }
   ],
   "source": [
    "# Ask a follow-up question to test context awareness\n",
    "chat_with_bot(\"What are some applications of this technology?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Chat Interface\n",
    "\n",
    "Let's create a more interactive interface using IPython widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (9.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "# Install ipywidgets if not already installed\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except ImportError:\n",
    "    !pip install ipywidgets\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/704y51zd6fb_qq27pnjr39xm0000gn/T/ipykernel_20721/1000037502.py:71: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  text_input.on_submit(on_enter)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8686d47df5ba43eaade28038933962ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61f8a8c6370469d9975e4d4fa47cf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Message:', layout=Layout(width='80%'), placeholder='Type your messa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7057846c2d34fcd954128ce1f8c0b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Reset Chat', icon='refresh', style=ButtonStyle(), tooltip='Reset c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create widgets for the chat interface\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your message here...',\n",
    "    description='Message:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    disabled=False,\n",
    "    button_style='primary',\n",
    "    tooltip='Send message',\n",
    "    icon='paper-plane'\n",
    ")\n",
    "\n",
    "reset_button = widgets.Button(\n",
    "    description='Reset Chat',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Reset conversation',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "output = widgets.Output(layout={'border': '1px solid black', 'width': '80%', 'height': '300px', 'overflow_y': 'auto'})\n",
    "\n",
    "# Display initial message\n",
    "with output:\n",
    "    display(HTML(\"<b>Bot:</b> Hello! I'm your AI assistant. How can I help you today?\"))\n",
    "\n",
    "# Define button click handlers\n",
    "def on_send_button_clicked(b):\n",
    "    message = text_input.value\n",
    "    if message.strip() == '':\n",
    "        return\n",
    "    \n",
    "    # Clear input field\n",
    "    text_input.value = ''\n",
    "    \n",
    "    # Display user message\n",
    "    with output:\n",
    "        display(HTML(f\"<b>User:</b> {message}\"))\n",
    "    \n",
    "    # Get bot response\n",
    "    response = chatbot.generate_response(message)\n",
    "    \n",
    "    # Display bot response\n",
    "    with output:\n",
    "        display(HTML(f\"<b>Bot:</b> {response}\"))\n",
    "\n",
    "def on_reset_button_clicked(b):\n",
    "    # Reset conversation\n",
    "    chatbot.reset_conversation()\n",
    "    \n",
    "    # Clear output\n",
    "    output.clear_output()\n",
    "    \n",
    "    # Display initial message\n",
    "    with output:\n",
    "        display(HTML(\"<b>Bot:</b> Hello! I'm your AI assistant. How can I help you today?\"))\n",
    "\n",
    "# Connect the handlers to the buttons\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "reset_button.on_click(on_reset_button_clicked)\n",
    "\n",
    "# Handle Enter key in text input\n",
    "def on_enter(sender):\n",
    "    on_send_button_clicked(None)\n",
    "\n",
    "text_input.on_submit(on_enter)\n",
    "\n",
    "# Display the widgets\n",
    "display(output)\n",
    "display(widgets.HBox([text_input, send_button]))\n",
    "display(reset_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Customizing the Chatbot\n",
    "\n",
    "Let's explore how to customize the chatbot with different models and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4595059f17441d94e3dad26dc80eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395f1e7af9c44a37ad6abce47d8ebb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d920b3f2fa7476a81ec028b6a4a5e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495384427e58454596674bffea5b27a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e680d774f0b34e168563a70d3df0d7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731ec43c338a4271829e3d898f22291d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521e43a0c3f94b3e8ffc73f95f1a2c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ecd1cd53824e32bc3ab47474d4b203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt2\n",
      "  Available: True\n",
      "  Requires GPU: False\n",
      "  GPU Available: False\n",
      "\n",
      "Model: distilgpt2\n",
      "  Available: True\n",
      "  Requires GPU: False\n",
      "  GPU Available: False\n",
      "\n",
      "Model: microsoft/DialoGPT-small\n",
      "  Available: True\n",
      "  Requires GPU: False\n",
      "  GPU Available: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import model utilities\n",
    "from utils.model_utils import get_recommended_models\n",
    "\n",
    "# Get information about recommended models\n",
    "recommended_models = get_recommended_models()\n",
    "for model_name, info in recommended_models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  Available: {info['available']}\")\n",
    "    print(f\"  Requires GPU: {info['requires_gpu']}\")\n",
    "    print(f\"  GPU Available: {info['gpu_available']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a new configuration with different parameters\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m new_config = \u001b[43mConfig\u001b[49m()\n\u001b[32m      3\u001b[39m new_config.model_name = \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/DialoGPT-small\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# A model fine-tuned for dialogue\u001b[39;00m\n\u001b[32m      4\u001b[39m new_config.max_response_length = \u001b[32m100\u001b[39m  \u001b[38;5;66;03m# Longer responses\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a new configuration with different parameters\n",
    "new_config = Config()\n",
    "new_config.model_name = \"microsoft/DialoGPT-small\"  # A model fine-tuned for dialogue\n",
    "new_config.max_response_length = 100  # Longer responses\n",
    "new_config.temperature = 0.9  # More random/creative responses\n",
    "\n",
    "# Initialize a new chatbot with this configuration\n",
    "print(\"Initializing new chatbot with DialoGPT-small...\")\n",
    "try:\n",
    "    dialogpt_chatbot = Chatbot(new_config)\n",
    "    print(\"DialoGPT chatbot initialized successfully!\")\n",
    "    \n",
    "    # Try a conversation with the new model\n",
    "    print(\"\\nUser: Hello, who are you?\")\n",
    "    response = dialogpt_chatbot.generate_response(\"Hello, who are you?\")\n",
    "    print(f\"Bot: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing DialoGPT chatbot: {e}\")\n",
    "    print(\"Continuing with the original chatbot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launching the Web Interface\n",
    "\n",
    "The chatbot project includes a web interface built with Flask. Let's see how to launch it from Jupyter.\n",
    "\n",
    "**Note:** Running this cell will start a web server. You'll need to access it in a browser at the URL shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to launch the web interface\n",
    "def launch_web_interface(port=8888):\n",
    "    from app.web_interface import start_web_server\n",
    "    print(f\"Starting web server on port {port}...\")\n",
    "    print(f\"Access the web interface at: http://localhost:{port}\")\n",
    "    print(\"Press Ctrl+C in the cell output to stop the server when done.\")\n",
    "    \n",
    "    # Start the web server with our chatbot instance\n",
    "    start_web_server(chatbot, host='0.0.0.0', port=port, debug=True)\n",
    "\n",
    "# Uncomment the next line to launch the web interface\n",
    "# launch_web_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Conversations\n",
    "\n",
    "The chatbot can save conversation history. Let's see how to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current conversation history\n",
    "conversation_history = chatbot.get_conversation_history()\n",
    "print(f\"Conversation has {len(conversation_history)} messages\")\n",
    "\n",
    "# Display the conversation\n",
    "for i, message in enumerate(conversation_history):\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    print(f\"{i+1}. {role.capitalize()}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "1. Set up and initialize the LLM chatbot\n",
    "2. Interact with the chatbot in different ways\n",
    "3. Customize the chatbot configuration\n",
    "4. Launch the web interface\n",
    "5. Access conversation history\n",
    "\n",
    "You can now use this chatbot in your own projects, customize it further, or extend its functionality. The modular design makes it easy to adapt to different use cases.\n",
    "\n",
    "For more information, check out the project documentation in the README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
